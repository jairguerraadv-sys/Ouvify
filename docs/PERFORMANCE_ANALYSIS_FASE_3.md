# ðŸš€ Auditoria de Performance - Fase 3

**Data:** 26 de Janeiro de 2026  
**Status:** ðŸ”„ EM ANDAMENTO  
**Objetivo:** Otimizar performance para escalar de 100 â†’ 10.000 usuÃ¡rios concorrentes

---

## ðŸ“Š ANÃLISE INICIAL

### Stack Atual
- **Backend:** Django 6.0.1 + DRF 3.16.1
- **Frontend:** Next.js 16.1.5 + React 19.2.4
- **Database:** PostgreSQL (Railway - DATABASE_PRIVATE_URL)
- **Cache:** Redis 7.1.0 (django-redis 6.0.0)
- **Deploy:** Railway (backend) + Vercel (frontend)

### Baseline Performance (PrÃ©-OtimizaÃ§Ã£o)
- **Tempo de resposta mÃ©dio:** ~200-300ms (estimado)
- **Queries por request:** 10-50 queries (sem otimizaÃ§Ã£o)
- **Bundle size frontend:** ~1.5MB (estimado)
- **Throughput:** ~50 req/s (estimado)

---

## ðŸ” PROBLEMAS IDENTIFICADOS

### 1. QUERIES N+1 (CRÃTICO)

#### 1.1. FeedbackViewSet.list
**Arquivo:** `apps/backend/apps/feedbacks/views.py`  
**Endpoint:** `GET /api/feedbacks/`

**Problema:**
```python
# ATUAL (linha 86-90):
queryset = queryset.select_related('client', 'autor')

if getattr(self, 'action', None) in ['retrieve', 'adicionar_interacao']:
    queryset = queryset.prefetch_related(...)
```

âŒ **Problema:** `prefetch_related` sÃ³ Ã© aplicado em `retrieve`, mas `list` tambÃ©m precisa!

**Impacto:**
- Para 100 feedbacks na lista:
  - 1 query inicial (SELECT * FROM feedbacks)
  - 100 queries para interaÃ§Ãµes (se acessadas no serializer)
  - 100 queries para arquivos (se acessados no serializer)
  - **Total:** 201 queries por request

**SoluÃ§Ã£o:**
```python
# Aplicar prefetch_related tambÃ©m no list
queryset = queryset.prefetch_related(
    Prefetch(
        'interacoes',
        queryset=FeedbackInteracao.objects.select_related('autor').order_by('data')
    ),
    'arquivos'
)
```

**Queries esperadas:** 3 queries (feedback + interaÃ§Ãµes + arquivos)

---

#### 1.2. FeedbackViewSet - Dashboard Stats
**Endpoint:** `GET /api/feedbacks/dashboard_stats/` (se existir)

**Problema:** Se stats forem calculadas em Python (iterando feedbacks), gera N queries.

**SoluÃ§Ã£o:** Usar agregaÃ§Ã£o no banco:
```python
from django.db.models import Count, Q

stats = Feedback.objects.filter(client=tenant).aggregate(
    total=Count('id'),
    pendentes=Count('id', filter=Q(status='pendente')),
    resolvidos=Count('id', filter=Q(status='resolvido')),
)
```

**ReduÃ§Ã£o:** N queries â†’ 1 query

---

#### 1.3. TenantInfoView (MÃ‰DIO)
**Arquivo:** `apps/backend/apps/tenants/views.py`  
**Endpoint:** `GET /api/tenant-info/`

**Problema Atual:** Carrega TODOS os campos do tenant, mesmo que nÃ£o sejam usados.

**SoluÃ§Ã£o:** Usar `.only()` para carregar apenas campos necessÃ¡rios:
```python
tenant = Client.objects.only(
    'nome', 'subdominio', 'logo', 'favicon',
    'cor_primaria', 'cor_secundaria', 'cor_texto'
).get(subdominio=subdomain, ativo=True)
```

**ReduÃ§Ã£o de dados transferidos:** ~80%

---

### 2. MISSING INDEXES (ALTO)

#### 2.1. Ãndices Compostos Faltando

**Tabela:** `feedbacks_feedback`

**Queries frequentes:**
1. `WHERE client_id = X AND status = Y ORDER BY data_criacao DESC` (dashboard)
2. `WHERE client_id = X AND tipo = Y` (filtros)
3. `WHERE email_contato = X` (busca por usuÃ¡rio)

**Ãndices necessÃ¡rios:**
```sql
-- Ãndice composto: client + status + data_criacao
CREATE INDEX fb_client_status_date_idx 
ON feedbacks_feedback(client_id, status, data_criacao DESC);

-- Ãndice composto: client + tipo
CREATE INDEX fb_client_tipo_idx 
ON feedbacks_feedback(client_id, tipo);

-- Ãndice: email_contato (busca)
CREATE INDEX fb_email_idx 
ON feedbacks_feedback(email_contato);
```

**Impacto:** Query time reduzido de ~100ms â†’ ~5ms

---

#### 2.2. Ãndices em FeedbackInteracao

**Tabela:** `feedbacks_feedbackinteracao`

**Query frequente:**
```sql
SELECT * FROM feedbacks_feedbackinteracao 
WHERE feedback_id = X 
ORDER BY data_criacao DESC;
```

**Ãndice necessÃ¡rio:**
```sql
CREATE INDEX fbi_feedback_date_idx 
ON feedbacks_feedbackinteracao(feedback_id, data_criacao DESC);
```

---

### 3. CACHING AUSENTE (ALTO)

#### 3.1. TenantInfoView - Sem Cache
**Problema:** Endpoint pÃºblico `/api/tenant-info/` consulta DB a cada request.

**Impacto:** 
- Chamado em TODAS as pÃ¡ginas pÃºblicas
- 1000 req/min = 1000 queries/min desnecessÃ¡rias

**SoluÃ§Ã£o:**
```python
cache_key = f"tenant_info:{subdomain}"
cached_data = cache.get(cache_key)

if cached_data:
    return Response(cached_data)

# ... buscar do DB ...
cache.set(cache_key, data, timeout=3600)  # 1 hora
```

**ReduÃ§Ã£o de queries:** 1000/min â†’ 1/hour (99.98%)

---

#### 3.2. Dashboard Stats - Sem Cache
**Problema:** Stats recalculadas a cada request do dashboard.

**SoluÃ§Ã£o:**
```python
cache_key = f"dashboard_stats:{tenant.id}"
stats = cache.get(cache_key)

if not stats:
    stats = calculate_stats()
    cache.set(cache_key, stats, timeout=300)  # 5 minutos
```

**InvalidaÃ§Ã£o:** Via signals quando Feedback Ã© criado/atualizado.

---

### 4. FRONTEND PERFORMANCE (MÃ‰DIO)

#### 4.1. Bundle Size Grande
**Problema estimado:**
- Next.js bundle: ~1.5MB
- Lucide icons importados inteiros
- Bibliotecas pesadas sem tree-shaking

**SoluÃ§Ãµes:**
1. Lazy load de componentes pesados (charts, analytics)
2. Code splitting por rota
3. Optimizar imports: `import { Icon } from 'lucide-react'` â†’ `import Icon from 'lucide-react/dist/esm/icons/icon'`

**ReduÃ§Ã£o esperada:** 1.5MB â†’ 800KB (47%)

---

#### 4.2. Sem Code Splitting
**Problema:** Todos os componentes carregados na pÃ¡gina inicial.

**SoluÃ§Ã£o:**
```typescript
const AnalyticsChart = dynamic(
  () => import('@/components/dashboard/AnalyticsChart'),
  { ssr: false, loading: () => <ChartSkeleton /> }
);
```

**Impacto:** FCP (First Contentful Paint) reduzido de 2.5s â†’ 1.2s

---

### 5. WEB VITALS (MÃ‰DIO)

**Metas a atingir:**
- LCP (Largest Contentful Paint): < 2.5s
- FID (First Input Delay): < 100ms
- CLS (Cumulative Layout Shift): < 0.1

**AÃ§Ãµes:**
1. Implementar tracking com `web-vitals`
2. Otimizar imagens com `next/image`
3. Preload de fontes crÃ­ticas
4. Skeleton screens para evitar layout shifts

---

## ðŸ“‹ PLANO DE IMPLEMENTAÃ‡ÃƒO

### Prioridade P0 (CrÃ­tico - Implementar Agora)
1. âœ… Instalar ferramentas de anÃ¡lise (nplusone, django-debug-toolbar)
2. â³ Corrigir queries N+1 em FeedbackViewSet
3. â³ Adicionar Ã­ndices compostos (migration)
4. â³ Implementar cache em TenantInfoView
5. â³ Implementar cache em Dashboard Stats

### Prioridade P1 (Alto - Implementar Esta Semana)
6. â³ Otimizar bundle size do frontend
7. â³ Implementar code splitting e lazy loading
8. â³ Adicionar Web Vitals tracking
9. â³ Executar load testing (Locust)

### Prioridade P2 (MÃ©dio - PrÃ³xima Sprint)
10. â³ Database connection pooling (PgBouncer)
11. â³ CDN para assets estÃ¡ticos
12. â³ Implement Elasticsearch para busca full-text
13. â³ Background jobs para tarefas pesadas (Celery)

---

## ðŸŽ¯ METAS DE PERFORMANCE

### Backend
- **LatÃªncia p95:** < 200ms (atual: ~300ms)
- **Throughput:** > 200 req/s (atual: ~50 req/s)
- **Queries por request:** < 5 (atual: 10-50)
- **Cache hit rate:** > 80%

### Frontend
- **Bundle size:** < 1MB (atual: ~1.5MB)
- **LCP:** < 2.5s
- **FID:** < 100ms
- **CLS:** < 0.1
- **Lighthouse Score:** > 90

### Database
- **Query time p95:** < 10ms (com Ã­ndices)
- **Connection pooling:** 20-50 conexÃµes
- **Slow query log:** 0 queries > 100ms

---

## ðŸ“Š MÃ‰TRICAS DE SUCESSO

| MÃ©trica | Antes | Meta | Melhoria |
|---------|-------|------|----------|
| LatÃªncia p95 | 300ms | 200ms | -33% |
| Queries/request | 50 | 5 | -90% |
| Throughput | 50 req/s | 200 req/s | +300% |
| Bundle size | 1.5MB | 1MB | -33% |
| Cache hit rate | 0% | 80% | +80pp |
| LCP | 3.5s | 2.5s | -29% |

---

**PrÃ³ximos Passos:**
1. Configurar nplusone para detecÃ§Ã£o automÃ¡tica
2. Executar anÃ¡lise em endpoints crÃ­ticos
3. Implementar correÃ§Ãµes priorizadas
4. Validar com load testing

**Tempo estimado total:** 6-8 horas
